{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99aa31a",
   "metadata": {},
   "source": [
    "# 04 â€” Regression (Supervised) for PM2.5 (Tabular Time-Lag Features)\n",
    "Má»¥c tiÃªu:\n",
    "- Biáº¿n bÃ i toÃ¡n chuá»—i thá»i gian thÃ nh bÃ i toÃ¡n **há»“i quy cÃ³ giÃ¡m sÃ¡t**: dá»± Ä‘oÃ¡n PM2.5(t+h) tá»« Ä‘áº·c trÆ°ng táº¡i thá»i Ä‘iá»ƒm t.\n",
    "- Tháº¥y rÃµ: **leakage** vÃ  vÃ¬ sao pháº£i split theo thá»i gian.\n",
    "- So sÃ¡nh tÆ° duy há»“i quy (feature-based) vs ARIMA (time-series-based).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7583247",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ===== PARAMETERS =====\n",
    "USE_UCIMLREPO = False\n",
    "\n",
    "# Path to the raw ZIP (relative to project root)\n",
    "RAW_ZIP_PATH = 'data/raw/PRSA2017_Data_20130301-20170228.zip'\n",
    "\n",
    "def resolve_project_root(raw_zip_rel: str) -> Path:\n",
    "    \"\"\"Resolve project root robustly for both Jupyter and Papermill runs.\n",
    "\n",
    "    Papermill may execute notebooks with different working directories depending on how you run the pipeline.\n",
    "    This helper tries:\n",
    "      1) current working directory\n",
    "      2) parent directory\n",
    "      3) up to 3 levels up (useful when running from notebooks/ or notebooks/runs)\n",
    "    \"\"\"\n",
    "    cwd = Path.cwd().resolve()\n",
    "\n",
    "    # Common candidates\n",
    "    candidates = [cwd, cwd.parent]\n",
    "\n",
    "    # Climb up a few levels just in case\n",
    "    root = cwd\n",
    "    for _ in range(3):\n",
    "        candidates.append(root)\n",
    "        root = root.parent\n",
    "\n",
    "    for r in candidates:\n",
    "        if (r / raw_zip_rel).exists():\n",
    "            return r\n",
    "\n",
    "    # Fallback: keep cwd; downstream will raise a clear error message if missing\n",
    "    return cwd\n",
    "\n",
    "PROJECT_ROOT = resolve_project_root(RAW_ZIP_PATH)\n",
    "RAW_ZIP_ABS = str((PROJECT_ROOT / RAW_ZIP_PATH).resolve())\n",
    "\n",
    "LAG_HOURS = [1, 3, 24]\n",
    "HORIZON = 1              # dá»± Ä‘oÃ¡n trÆ°á»›c bao nhiÃªu giá»\n",
    "TARGET_COL = 'PM2.5'\n",
    "\n",
    "OUTPUT_REG_DATASET_PATH = 'data/processed/dataset_for_regression.parquet'\n",
    "CUTOFF = '2017-01-01'\n",
    "\n",
    "MODEL_OUT = 'regressor.joblib'\n",
    "METRICS_OUT = 'regression_metrics.json'\n",
    "PRED_SAMPLE_OUT = 'regression_predictions_sample.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd68087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.classification_library import Paths\n",
    "from src.regression_library import (\n",
    "    run_prepare_regression_dataset,\n",
    "    run_train_regression,\n",
    ")\n",
    "\n",
    "paths = Paths(project_root=PROJECT_ROOT)\n",
    "print('PROJECT_ROOT =', PROJECT_ROOT)\n",
    "print('RAW_ZIP_ABS =', RAW_ZIP_ABS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f725d87",
   "metadata": {},
   "source": [
    "## 1) Táº¡o dataset há»“i quy (lag features + time features + y = PM2.5(t+h))\n",
    "Trong lab, pháº§n nÃ y giÃºp sinh viÃªn hiá»ƒu cÃ¡ch táº¡o supervised dataset tá»« time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31edac2",
   "metadata": {},
   "source": [
    "## Q2.1 â€” VÃ¬ sao lag 24h thÆ°á»ng cÃ³ Ã½ nghÄ©a trong dá»± bÃ¡o PM2.5?\n",
    "\n",
    "**Giáº£i thÃ­ch:**\n",
    "\n",
    "1. **Chu ká»³ ngÃ y trong hoáº¡t Ä‘á»™ng con ngÆ°á»i**: \n",
    "   - Giao thÃ´ng cao Ä‘iá»ƒm vÃ o buá»•i sÃ¡ng (7-9h) vÃ  chiá»u (17-19h) láº·p láº¡i má»—i ngÃ y\n",
    "   - Hoáº¡t Ä‘á»™ng cÃ´ng nghiá»‡p, sáº£n xuáº¥t theo ca cá»‘ Ä‘á»‹nh\n",
    "   - Náº¥u Äƒn, sÆ°á»Ÿi áº¥m vÃ o cÃ¹ng khung giá» má»—i ngÃ y\n",
    "\n",
    "2. **Chu ká»³ ngÃ y trong Ä‘iá»u kiá»‡n khÃ­ tÆ°á»£ng**:\n",
    "   - Nhiá»‡t Ä‘á»™, Ä‘á»™ áº©m cÃ³ pattern láº·p láº¡i 24h (nÃ³ng ban ngÃ y, mÃ¡t ban Ä‘Ãªm)\n",
    "   - Lá»›p nghá»‹ch nhiá»‡t (inversion layer) thÆ°á»ng hÃ¬nh thÃ nh vÃ o sÃ¡ng sá»›m, giá»¯ Ã´ nhiá»…m gáº§n máº·t Ä‘áº¥t\n",
    "   - GiÃ³ thÆ°á»ng yáº¿u hÆ¡n vÃ o Ä‘Ãªm, máº¡nh hÆ¡n vÃ o ban ngÃ y\n",
    "\n",
    "3. **Tá»± tÆ°Æ¡ng quan cao**:\n",
    "   - NhÆ° Ä‘Ã£ tháº¥y trong EDA, autocorrelation táº¡i lag 24h váº«n ~0.7-0.8\n",
    "   - PM2.5 lÃºc 8h sÃ¡ng hÃ´m nay cÃ³ tÆ°Æ¡ng quan máº¡nh vá»›i PM2.5 lÃºc 8h sÃ¡ng hÃ´m qua\n",
    "   - Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh \"há»c\" Ä‘Æ°á»£c pattern láº·p láº¡i theo ngÃ y\n",
    "\n",
    "**Ã nghÄ©a thá»±c táº¿**: Sá»­ dá»¥ng PM2.5_lag24 nhÆ° má»™t Ä‘áº·c trÆ°ng cho phÃ©p mÃ´ hÃ¬nh biáº¿t \"hÃ´m qua cÃ¹ng giá» nhÆ° tháº¿ nÃ o\" - Ä‘Ã¢y lÃ  thÃ´ng tin ráº¥t cÃ³ giÃ¡ trá»‹ Ä‘á»ƒ dá»± Ä‘oÃ¡n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9788622",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = run_prepare_regression_dataset(\n",
    "    paths=paths,\n",
    "    use_ucimlrepo=USE_UCIMLREPO,\n",
    "    raw_zip_path=RAW_ZIP_ABS,\n",
    "    lag_hours=LAG_HOURS,\n",
    "    horizon=HORIZON,\n",
    "    target_col=TARGET_COL,\n",
    ")\n",
    "print('Saved:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8080bbe",
   "metadata": {},
   "source": [
    "## 2) Quick EDA cho dataset há»“i quy\n",
    "Gá»£i Ã½ cÃ¢u há»i ra quyáº¿t Ä‘á»‹nh:\n",
    "- Tá»‰ lá»‡ missing á»Ÿ cÃ¡c feature lag? (thÆ°á»ng thiáº¿u á»Ÿ Ä‘áº§u chuá»—i)\n",
    "- PM2.5 cÃ³ phÃ¢n phá»‘i lá»‡ch (skew) khÃ´ng? -> cÃ¢n nháº¯c log/clip (tuá»³ chá»n)\n",
    "- CÃ³ khÃ¡c biá»‡t theo *giá» trong ngÃ y* / *ngÃ y trong tuáº§n* khÃ´ng? (seasonality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = (PROJECT_ROOT / OUTPUT_REG_DATASET_PATH).resolve()\n",
    "df = pd.read_parquet(ds_path)\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "\n",
    "missing = df.isna().mean().sort_values(ascending=False).head(15)\n",
    "display(missing)\n",
    "\n",
    "plt.figure()\n",
    "pd.Series(df[TARGET_COL]).dropna().plot(kind='hist', bins=60)\n",
    "plt.title(f'Distribution of {TARGET_COL} (raw)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48671c",
   "metadata": {},
   "source": [
    "## 3) Train/Test theo thá»i gian + train regressor\n",
    "LÆ°u Ã½: mÃ´ hÃ¬nh há»“i quy á»Ÿ Ä‘Ã¢y lÃ  **feature-based** (dÃ¹ng lag + thá»i tiáº¿t).\n",
    "Pháº§n dá»± bÃ¡o chuá»—i thá»i gian *thuáº§n* sáº½ lÃ m báº±ng ARIMA á»Ÿ notebook káº¿ tiáº¿p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3ba76",
   "metadata": {},
   "source": [
    "## Q2.2 â€” VÃ¬ sao pháº£i chia train/test theo thá»i gian (cutoff)?\n",
    "\n",
    "**Váº¥n Ä‘á» cá»§a Random Split trong Time Series:**\n",
    "\n",
    "Náº¿u chÃºng ta chia train/test ngáº«u nhiÃªn (random split) nhÆ° trong bÃ i toÃ¡n classification/regression thÃ´ng thÆ°á»ng:\n",
    "- Dá»¯ liá»‡u tá»« 2017 (tÆ°Æ¡ng lai) cÃ³ thá»ƒ náº±m trong train set\n",
    "- Dá»¯ liá»‡u tá»« 2014 (quÃ¡ khá»©) cÃ³ thá»ƒ náº±m trong test set\n",
    "- MÃ´ hÃ¬nh sáº½ \"nhÃ¬n tháº¥y tÆ°Æ¡ng lai\" trong quÃ¡ trÃ¬nh training â†’ **Time Leakage**\n",
    "\n",
    "**Time Leakage lÃ  gÃ¬?**\n",
    "- MÃ´ hÃ¬nh há»c Ä‘Æ°á»£c thÃ´ng tin tá»« tÆ°Æ¡ng lai mÃ  nÃ³ khÃ´ng nÃªn biáº¿t\n",
    "- Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ sáº½ \"Ä‘áº¹p giáº£\" (overly optimistic)\n",
    "- Khi triá»ƒn khai thá»±c táº¿, mÃ´ hÃ¬nh sáº½ hoáº¡t Ä‘á»™ng kÃ©m hÆ¡n nhiá»u\n",
    "\n",
    "**CÃ¡ch chia Ä‘Ãºng (Time-based Split vá»›i Cutoff):**\n",
    "```\n",
    "Train: 2013-03-01 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> 2016-12-31\n",
    "Test:                                 2017-01-01 â”€â”€> 2017-02-28\n",
    "                                      â†‘\n",
    "                                   CUTOFF\n",
    "```\n",
    "\n",
    "**Lá»£i Ã­ch:**\n",
    "1. MÃ´ phá»ng Ä‘Ãºng cÃ¡ch triá»ƒn khai thá»±c táº¿: train trÃªn quÃ¡ khá»©, dá»± bÃ¡o tÆ°Æ¡ng lai\n",
    "2. ÄÃ¡nh giÃ¡ chÃ¢n thá»±c (realistic evaluation)\n",
    "3. PhÃ¡t hiá»‡n váº¥n Ä‘á» concept drift (náº¿u pattern thay Ä‘á»•i theo thá»i gian)\n",
    "4. Lag features khÃ´ng bá»‹ \"nhÃ¬n trá»™m\" tÆ°Æ¡ng lai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run_train_regression(\n",
    "    paths=paths,\n",
    "    cutoff=CUTOFF,\n",
    "    model_out=MODEL_OUT,\n",
    "    metrics_out=METRICS_OUT,\n",
    "    preds_out=PRED_SAMPLE_OUT,\n",
    ")\n",
    "\n",
    "print('Metrics:')\n",
    "print(json.dumps(out['metrics'], ensure_ascii=False, indent=2))\n",
    "pred_df = out['pred_df']\n",
    "display(pred_df.head())\n",
    "\n",
    "# Plot a small window for storytelling\n",
    "sample = pred_df.dropna().iloc[:500].copy()\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(sample['datetime'], sample['y_true'], label='Actual')\n",
    "plt.plot(sample['datetime'], sample['y_pred'], label='Predicted')\n",
    "plt.title('Regression: Actual vs Predicted (sample)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cae13a",
   "metadata": {},
   "source": [
    "### Diá»…n giáº£i Ä‘á»“ thá»‹ Actual vs Predicted (Regression)\n",
    "\n",
    "**Nháº­n xÃ©t tá»« Ä‘á»“ thá»‹:**\n",
    "\n",
    "1. **BÃ¡m sÃ¡t xu hÆ°á»›ng tá»‘t:** MÃ´ hÃ¬nh há»“i quy (sá»­ dá»¥ng lag features) theo dÃµi khÃ¡ tá»‘t cÃ¡c biáº¿n Ä‘á»™ng cá»§a PM2.5. ÄÆ°á»ng Predicted (cam) thÆ°á»ng Ä‘i sÃ¡t Ä‘Æ°á»ng Actual (xanh), Ä‘áº·c biá»‡t trong cÃ¡c giai Ä‘oáº¡n á»•n Ä‘á»‹nh.\n",
    "\n",
    "2. **Pháº£n á»©ng vá»›i spike:** TÆ°Æ¡ng tá»± ARIMA, mÃ´ hÃ¬nh cÃ³ xu hÆ°á»›ng **under-predict** táº¡i cÃ¡c Ä‘á»‰nh PM2.5 cao. Äiá»u nÃ y do mÃ´ hÃ¬nh tuyáº¿n tÃ­nh khÃ³ báº¯t Ä‘Æ°á»£c cÃ¡c giÃ¡ trá»‹ cá»±c Ä‘oan náº±m ngoÃ i vÃ¹ng dá»¯ liá»‡u huáº¥n luyá»‡n.\n",
    "\n",
    "3. **Lag 1h chi phá»‘i máº¡nh:** Do sá»­ dá»¥ng PM2.5_lag1 (giÃ¡ trá»‹ 1 giá» trÆ°á»›c), dá»± bÃ¡o cÃ³ xu hÆ°á»›ng \"cháº­m pha\" â€” khi PM2.5 tÄƒng Ä‘á»™t ngá»™t, dá»± bÃ¡o cáº§n 1-2 giá» Ä‘á»ƒ \"Ä‘uá»•i ká»‹p\".\n",
    "\n",
    "4. **Ã nghÄ©a thá»±c tiá»…n:** MÃ´ hÃ¬nh regression vá»›i lag features phÃ¹ há»£p cho dá»± bÃ¡o ngáº¯n háº¡n (horizon 1-3h). Äá»ƒ cáº£i thiá»‡n vá»›i spike, cÃ³ thá»ƒ thá»­ thÃªm features tá»« thá»i tiáº¿t (WSPM, RAIN) hoáº·c sá»­ dá»¥ng ensemble methods (Random Forest, Gradient Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db7fa8",
   "metadata": {},
   "source": [
    "## Q2.3 â€” PhÃ¢n biá»‡t RMSE vÃ  MAE: Khi nÃ o RMSE cao hÆ¡n nhiá»u?\n",
    "\n",
    "**CÃ´ng thá»©c:**\n",
    "- **MAE** (Mean Absolute Error) = $\\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
    "- **RMSE** (Root Mean Squared Error) = $\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$\n",
    "\n",
    "**Sá»± khÃ¡c biá»‡t:**\n",
    "| Äáº·c Ä‘iá»ƒm | MAE | RMSE |\n",
    "|----------|-----|------|\n",
    "| CÃ¡ch xá»­ lÃ½ outliers | Ãt nháº¡y | Ráº¥t nháº¡y (do bÃ¬nh phÆ°Æ¡ng) |\n",
    "| ÄÆ¡n vá»‹ | CÃ¹ng Ä‘Æ¡n vá»‹ vá»›i y | CÃ¹ng Ä‘Æ¡n vá»‹ vá»›i y |\n",
    "| Pháº¡t sai sá»‘ lá»›n | Tuyáº¿n tÃ­nh | Báº­c hai (pháº¡t náº·ng hÆ¡n) |\n",
    "\n",
    "**Khi nÃ o RMSE >> MAE?**\n",
    "1. Khi cÃ³ **cÃ¡c spike (Ä‘á»‰nh Ã´ nhiá»…m)** mÃ  mÃ´ hÃ¬nh dá»± bÃ¡o sai\n",
    "2. Khi mÃ´ hÃ¬nh dá»± bÃ¡o **lá»‡ch lá»›n á»Ÿ má»™t sá»‘ thá»i Ä‘iá»ƒm** nhÆ°ng Ä‘Ãºng á»Ÿ pháº§n lá»›n cÃ²n láº¡i\n",
    "3. Khi cÃ³ **outliers** trong dá»¯ liá»‡u hoáº·c dá»± bÃ¡o\n",
    "\n",
    "**VÃ­ dá»¥ thá»±c táº¿ vá»›i PM2.5:**\n",
    "- Náº¿u RMSE = 25, MAE = 12 â†’ Tá»· lá»‡ RMSE/MAE â‰ˆ 2.1\n",
    "- Äiá»u nÃ y cho tháº¥y cÃ³ má»™t sá»‘ Ä‘iá»ƒm dá»± bÃ¡o sai nhiá»u (cÃ³ thá»ƒ lÃ  cÃ¡c spike PM2.5 vÃ o mÃ¹a Ä‘Ã´ng)\n",
    "- MÃ´ hÃ¬nh \"trung bÃ¬nh\" khÃ¡ tá»‘t (MAE tháº¥p) nhÆ°ng \"sai lá»›n\" á»Ÿ má»™t sá»‘ Ä‘iá»ƒm quan trá»ng (RMSE cao hÆ¡n)\n",
    "\n",
    "**Ã nghÄ©a cho dá»± bÃ¡o cháº¥t lÆ°á»£ng khÃ´ng khÃ­:**\n",
    "- Náº¿u má»¥c tiÃªu lÃ  **cáº£nh bÃ¡o sá»›m cÃ¡c Ä‘á»£t Ã´ nhiá»…m nghiÃªm trá»ng** â†’ RMSE quan trá»ng hÆ¡n (vÃ¬ cáº§n dá»± bÃ¡o Ä‘Ãºng spike)\n",
    "- Náº¿u má»¥c tiÃªu lÃ  **dá»± bÃ¡o trung bÃ¬nh hÃ ng ngÃ y** â†’ MAE cÃ³ thá»ƒ Ä‘á»§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhÃ¢n tÃ­ch RMSE vs MAE - TÃ¬m cÃ¡c Ä‘iá»ƒm mÃ  mÃ´ hÃ¬nh dá»± bÃ¡o sai nhiá»u\n",
    "print(\"=\"*60)\n",
    "print(\"PHÃ‚N TÃCH RMSE VS MAE - TÃŒM CÃC ÄIá»‚M Dá»° BÃO SAI NHIá»€U\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TÃ­nh error cho tá»«ng Ä‘iá»ƒm\n",
    "pred_analysis = pred_df.dropna().copy()\n",
    "pred_analysis['error'] = pred_analysis['y_true'] - pred_analysis['y_pred']\n",
    "pred_analysis['abs_error'] = np.abs(pred_analysis['error'])\n",
    "pred_analysis['squared_error'] = pred_analysis['error'] ** 2\n",
    "\n",
    "# Thá»‘ng kÃª error\n",
    "print(f\"\\nðŸ“Š Thá»‘ng kÃª sai sá»‘:\")\n",
    "print(f\"   MAE:  {pred_analysis['abs_error'].mean():.2f}\")\n",
    "print(f\"   RMSE: {np.sqrt(pred_analysis['squared_error'].mean()):.2f}\")\n",
    "print(f\"   Tá»· lá»‡ RMSE/MAE: {np.sqrt(pred_analysis['squared_error'].mean()) / pred_analysis['abs_error'].mean():.2f}\")\n",
    "\n",
    "# TÃ¬m cÃ¡c Ä‘iá»ƒm sai lá»›n nháº¥t (top 1%)\n",
    "threshold_99 = pred_analysis['abs_error'].quantile(0.99)\n",
    "large_errors = pred_analysis[pred_analysis['abs_error'] >= threshold_99]\n",
    "\n",
    "print(f\"\\nâš ï¸ CÃ¡c Ä‘iá»ƒm sai lá»›n nháº¥t (top 1%, error >= {threshold_99:.1f}):\")\n",
    "print(f\"   Sá»‘ Ä‘iá»ƒm: {len(large_errors)}\")\n",
    "print(f\"   Error trung bÃ¬nh táº¡i cÃ¡c Ä‘iá»ƒm nÃ y: {large_errors['abs_error'].mean():.2f}\")\n",
    "\n",
    "# Visualize phÃ¢n phá»‘i error\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Histogram cá»§a absolute error\n",
    "ax1 = axes[0]\n",
    "pred_analysis['abs_error'].hist(bins=50, ax=ax1, alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(threshold_99, color='red', linestyle='--', label=f'Q99={threshold_99:.1f}')\n",
    "ax1.set_xlabel('Absolute Error')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('PhÃ¢n phá»‘i Absolute Error')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Scatter: y_true vs error (Ä‘á»ƒ tháº¥y error cao á»Ÿ spike)\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(pred_analysis['y_true'], pred_analysis['abs_error'], alpha=0.3, s=5)\n",
    "ax2.axhline(threshold_99, color='red', linestyle='--', label='Q99 threshold')\n",
    "ax2.set_xlabel('Actual PM2.5')\n",
    "ax2.set_ylabel('Absolute Error')\n",
    "ax2.set_title('Error theo má»©c PM2.5 thá»±c táº¿')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Time series cá»§a error Ä‘á»ƒ tháº¥y khi nÃ o sai nhiá»u\n",
    "ax3 = axes[2]\n",
    "ax3.plot(pred_analysis['datetime'], pred_analysis['abs_error'], linewidth=0.5, alpha=0.7)\n",
    "ax3.axhline(threshold_99, color='red', linestyle='--', label='Q99 threshold')\n",
    "ax3.set_xlabel('Thá»i gian')\n",
    "ax3.set_ylabel('Absolute Error')\n",
    "ax3.set_title('Error theo thá»i gian')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Nháº­n xÃ©t:\")\n",
    "print(\"   - Error lá»›n thÆ°á»ng xáº£y ra khi PM2.5 thá»±c táº¿ CAO (spike Ã´ nhiá»…m)\")\n",
    "print(\"   - MÃ´ hÃ¬nh cÃ³ xu hÆ°á»›ng under-predict táº¡i cÃ¡c Ä‘á»‰nh Ã´ nhiá»…m\")\n",
    "print(\"   - ÄÃ¢y lÃ  lÃ½ do RMSE > MAE: cÃ¡c spike lÃ m tÄƒng squared error Ä‘Ã¡ng ká»ƒ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
